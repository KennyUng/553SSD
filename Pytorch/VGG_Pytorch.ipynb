{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_Pytorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaVAq9H4Pol"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdLo7z6zHb6Q",
        "outputId": "4e8a736e-5420-4ad6-c646-c36096f34963"
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq30XJbU-llC",
        "outputId": "c9d2240f-79ca-4fc1-961f-f96e33079667"
      },
      "source": [
        "# Transforms allow us to process the image to the correct model specifications prior to training\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomResizedCrop(224),\n",
        "     transforms.ToTensor, # converts to from np array to tensor\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Load our training and test sets via torchvision\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Dataloader allows us to minibatch our data when we pass it through our model\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# We do the same thing with the test set but we opt not to shuffle since we won't pass the test set more than once anyways\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z5dziZK_97q"
      },
      "source": [
        "# Implement VGG16 Model:\n",
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG16, self).__init__()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "    self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "    self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "    self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "    self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "    self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "    self.fc1 = nn.Linear(25088, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, 10)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    xb = F.relu(self.conv1_1(xb))\n",
        "    xb = F.relu(self.conv1_2(xb))\n",
        "    xb = self.maxpool(xb)\n",
        "\n",
        "    xb = F.relu(self.conv2_1(xb))\n",
        "    xb = F.relu(self.conv2_2(xb))\n",
        "    xb = self.maxpool(xb)\n",
        "\n",
        "    xb = F.relu(self.conv3_1(xb))\n",
        "    xb = F.relu(self.conv3_2(xb))\n",
        "    xb = F.relu(self.conv3_3(xb))\n",
        "    xb = self.maxpool(xb)\n",
        "\n",
        "    xb = F.relu(self.conv4_1(xb))\n",
        "    xb = F.relu(self.conv4_2(xb))\n",
        "    xb = F.relu(self.conv4_3(xb))\n",
        "    xb = self.maxpool(xb)\n",
        "\n",
        "    xb = F.relu(self.conv5_1(xb))\n",
        "    xb = F.relu(self.conv5_2(xb))\n",
        "    xb = F.relu(self.conv5_3(xb))\n",
        "    xb = self.maxpool(xb)\n",
        "\n",
        "    xb = xb.reshape(xb.shape[0], -1)\n",
        "\n",
        "    xb = F.relu(self.fc1(xb))\n",
        "    xb = F.dropout(xb, 0.5)\n",
        "\n",
        "    xb = F.relu(self.fc2(xb))\n",
        "    xb = F.dropout(xb, 0.5)\n",
        "\n",
        "    xb = F.relu(self.fc3(xb))\n",
        "\n",
        "    return xb"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyo0ATADPsP-",
        "outputId": "678f9e43-1796-4e68-93fe-e3f3f3b41af4"
      },
      "source": [
        "model = VGG16()\n",
        "model.to(dev)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjQUtMGxBMQQ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def fit(epochs, model, opt, train_dl):\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_dl, 0):\n",
        "      inputs, labels = data\n",
        "      opt.zero_grad()\n",
        "      pred = model(inputs)\n",
        "      loss = criterion(pred, labels)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      running_loss += loss.item()\n",
        "      if i % 2000 == 1999:\n",
        "        print('[%d, %5d] loss: %.3f'%\n",
        "              (epoch + 1, i + 1, running_loss/2000))\n",
        "        running_loss = 0.0\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1qXIRZTQPBZ"
      },
      "source": [
        "fit(1, model, optimizer, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff6LTZGBdBoA"
      },
      "source": [
        "for epoch in range(2):\n",
        "  running_loss = 0\n",
        "  model.train()\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(dev) # make the data a cuda tensor\n",
        "    labels = labels.to(dev) # make the labels a cuda tensor\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(inputs)\n",
        "    loss = criterion(pred, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print('[%d, %5d] loss: %.3f'%\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "    optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X13wBsSHat7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}